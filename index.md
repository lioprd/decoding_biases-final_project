# Racial Biases in AI Gahaku and Image-to-image GAN Art 
_How can AI Gahaku and Image-to-Image GAN art reproduce racial biases?_  

* [Introduction](#introduction)
* [Literature review and approach](#literature-review-and-approach)
* [Methodology](#methodology)
* [Findings](#findings)
* [Discussion](#discussion)
* [Conclusion and Limitations](#conclusion-and-limitations)
* [References](#references)
* [Appendices](#appendices)

## Introduction
<p align="justify">The introduction of GPT-3 and other neural network machine learning models reignited a tremendous interest regarding Artificial Intelligence and its potentials in various domains of application. Recently, AI generated art has experienced a wave of popularity, allowing users to create paintings, music, poetry, and eventually raising a lot of questions in the art community and in ethical debates. Our object of study, “AI Gahaku” is an AI artist who creates paintings in numerous styles based on photos submitted by user. Created by the Japanese full-stack developer Sato, the AI is most likely based on an unpaired image-to-image translation model using Generative Adversarial Networks (GANs). These models can produce compelling results even when paired training data is lacking as they only require unlabelled input and output data (Zhu et al., 2020). This technology, if highly impressive and entertaining, has shown some limitations, especially in face-transforming AI platforms, such as AI Gahaku. The most striking and serious limitation might be the racial biases displayed in AI Gahaku and similar apps. Indeed, when presented with pictures from non-white individuals, the AI model tends to be  remove “non-white” features in the generated images. Thus, following a qualitative methodological approach, our study aims to observe the extent to which face-transforming AIs have a bias towards minorities. Such phenomenon resonates greatly with broader social and racial issues, especially processes of underrepresentation and the invisibilization of minority groups. </p>

## Literature review and approach
<p align="justify">As mentioned earlier, we are investigating the possible racial biases present in the AI platform “AI Gahaku”. This application offers to its users the possibility to create a seemingly painted portrait, based on a picture, according to various classical methods of painting. Such offer is contained in the scope of “generative art”. Generative art as a whole refers to “art that in part or in whole has been created by the use of an autonomous system” (Srinivasan and Uchino, 2020), more precisely, the particular structure of “AI Gahaku” falls under the scope of the most common sub-genre of generative art which is computer generated art, more commonly called CG-Art. CG-Art describes an artwork generated by a computer program running by itself, with no interference from a human artist (Boden and Edmonds, 2009), thus mostly by AI. This fairly recent form of art creation has hit a wave of popularity in the late 2020s, with noticeably the commercialization of various apps generating “painted” portraits, such as the object of our study “AI Gahaku” in 2019. In terms of structure, we can safely identify “AI Gahaku” as a Generative Adversarial Network (GAN) (Ian J. Goodfellow et al., 2014). This type of machine learning is based on two datasets learning from each other unsupervised, creating a new product, it can be an image or a music for example, in the same style as the training set which could explain the popularity of GANs in platforms resembling “AI Gahaku”. </p>
  
<p align="justify">	The phenomenon of generative art raised a lot of questions regarding the sheer essence of art; can a computer truly create a piece of art ? This debate, otherwise fascinating, is not the matter of our analysis but more of a starting point. Indeed, some authors, such as Aaron Hertzmann, argue that the process of creating “art” is primarily social, and thus can not be achieved by a computer program such an AI (Hertzmann, 2018). But if generated art is not driven by social consideration, we argue that it may reflect social concerns and issues, and in the case of AI Gahaku racial biases and white washing. The main general argument for such biases could be the pre-existing human prejudices and preconceptions embedded in the dataset (Young, 2019). In scientific reasoning, we rely heavily on Ramya Srinivasan and Kanji Uchino’s theory regarding the reasons behind such racial biases in generative portrait AI. The authors go into details about two types of bias in the algorithm that can result in addition of the dataset bias in such issues, which are the transportability bias and the selection bias. The latter refers to the bias induced in the algorithm by a preferential selection of units in the data set. The authors go on to give the example of AI generating Renaissance style portraits. The AI will operate a selection of input images composed of Renaissance paintings, overwhelmingly representing white persons and thus, if given a picture of a person of color, will tend to whitewash them in the generated portrait. Transportability, on the other hand, defines “the conditions under which causal effects learned in experimental studies can be transferred into a new population in which only observational studies can be conducted.” This process can result in racial biases if the causal effects are not transferable across populations, which is observed by the authors when a specific AI, “GoArt”, used to convert photos in various styles, tints in blue or red the face of The Black Matriarch, a painting by Clementine Hunter, when asked to convert it in Expressionist or Byzantine style. </p>
  
<p align="justify"> The racial biases observed by the authors in CG-art and by ourselves in the case of AI-Gahaku have serious repercussions. As the artist Nina Baldwin beautifully put “Art is power. It can influence perception, opinion, and values.”, a racially biased CG-Art could thus create and communicate unethical values and uphold phenomenons of invisibilization of marginalized groups.</p>

## Methodology

<p align="justify">Our aim was to evaluate he accuracy of face-transforming AI on a diversity of faces by testing AI Gahaku’s accuracy on the faces of people of different ethnicities and identify whether it underperforms when creating images based on pictures of non-Caucasian people. </p>

<p align="justify"> <b> 1. </b> The first stage of our research consisted in gathering a dataset of faces from different ethnicities. To do so, we relied on the work of Kärkkäinen and Joo (2021) who constructed FairFace, a face attribute dataset balanced for race, gender, and age in the aim to resolve the biases that other public face image datasets such as previous datasets had toward Caucasian faces. They argue that most datasets tend to significantly underrepresent non-Caucasian faces and created an inclusive dataset to mitigate the race bias problem (Kärkkäinen and Joo, 2021, p. 1548). They defined the following seven race groups: Black, East Asian, Indian, Latino, Middle Eastern, Southeast Asian and White. We created 3 groups out of these seven categories, two treatment groups: Black and East Asian and a control group: White. We selected a total of 45 pictures (15 per ethnic group).

<p align="justify"> We assumed that since an overwhelming majority of the Northern Renaissance paintings feature white people, their representation will be the most accurate. For the control groups, we picked two groups that are typically underrepresented in this style to help us to assess whether a bias does indeed exist, and if yes whether it is similar for both groups or not.<br>

<p align="justify"> <b> 2. </b>  Second, we conducted research on various painting movements and eras, featured as filters by AI Gahaku in order to identify the two most relevant styles for comparison and any potential racial biases stemming from the artistic movement, rather than the algorithm itself. We settled on Early Renaissance (specifically the ME1 filter inspired by a painting by Antonello de Messine) and Contemporary Realism (specifically the WH2 filter) because the former is known for representing primarily European faces, while the latter style features more diversity in its portraits.
<div align="center"><img style="display: block;-webkit-user-select: none;margin: auto;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decoding_biases-final_project/main/assets/wh2me1.png"></div> 
<div align="center"><b>Preview image of the two styles on the AI Gahaku app </b></div>
<p align="justify"> We chose to compare the portraits generated through two different filters with different reputations regarding diversity, in order to better understand if any potential biases could be coming from the algorithm or rather from the filter’s dataset lacking diversity. If the difference in accuracy between the Early Renaissance paintings compared to the Contemporary Realism portraits were shocking, it would suggest the Early Renaissance dataset might be the root cause.

<p align="justify"><b> 3. </b> Finally, we converted the 45 faces into Renaissance paintings and into Contemporary Realism style paintings, comparing their accuracy amongst themselves and in comparison to the original faces. We also juxtaposed some of the original faces onto the AI-generated portraits to evaluate whether the face structure was deformed. </p>

## Findings

<p align="justify"> Before delving into the mismatches in the quality of the generations that could have been generated by a bias in the AI model, we need to address some aspects affecting all generations. It can notably be noticed that the shapes of the faces tend to be distorted or to present some artefacts (e.g.: #50, #2061, #4228). This is most likely due to formatting of the pictures in the fairface dataset, which crops pictures to only leave faces on the picture. As AI Gahaku generates portraits, it expands some cropped image to try and generate a full face, sometimes deforming faces. As our research focuses on biases in the faces of individuals, it will not be problematic for our analysis. Furthermore, the model produces subpar results for people with an open mouth, which occurred for some portraits, but it does not indicate a bias of the model. Another difficulty introduced by the fairface dataset is that the pictures are relatively small as the minimum size of a detected face can start at 50 by 50 pixels However, as mentioned by Kärkkäinen & Joo (2021, p. 1551), attributes are still recognizable so generations are still accurate enough to assess the presence of biases or not.
  
<p align="justify"> We will first assess the presence of biases on the Early Renaissance generations and followingly examine whether Contemporary Realism generations were less biased. As predicted by our initial hypothesis, the generated paintings show a certain degree of biases. The first group examined; Black people shows the most obvious bias which is linked to the skin tones of the generations. As can be seen on the figure XXX, all generations feature rather similar skin colours, which were used in Early Italian Renaissance by painters such as Antonello de Messina to depict white people. The gap is less striking on the generations that were made based on the East Asian group as their skin tones are less contrasted with the generated tone. However, after looking more in-depth at our generations, we can see that different undertones tend to be erased and the three group are uniformly depicted with white skin tones.

<img style="display: block;-webkit-user-select: none;margin: auto;cursor: zoom-in;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decodingbiases/main/assets/Figure_1.png">
  
<b>Original pictures and generations *Early Renaissance*, references of the images (link to right and top to bottom): #412, #1019, #4433, #1719</b>

<p align="justify">Besides the complete change of complexion, we observed that the model reproduces the face shape and most facial characteristics of the people rather accurately. To observe whether significant changes occurred, we juxtaposed original pictures with the AI generated images and observed which areas were misrepresented. We noted that eye shapes tend to not be represented accurately, especially for some members of the East Asian group. For instance, the epicanthal folds on the portraits #3718, #3623, #3974 and #4251 are replaced by rounder, greener eyes on the generated painting.  
  
<img style="display: block;-webkit-user-select: none;margin: auto;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decodingbiases/main/assets/Figure_2.png">

<b>Portrait #3718 & #3623 and juxtaposition of the real picture (black frame) on the generated portrait)</b> 

<p align="justify">Such modifications seem to be less prevalent when looking at our control group (white people) even though some individuals present artefacts around their eyes. A similar issue occurs for some portraits of the first group. 

<img style="display: block;-webkit-user-select: none;margin: auto;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decodingbiases/main/assets/figure_3.png">

<b> Portrait #119 & #5933 and juxtaposition of the real picture (black frame) on the generated portrait)</b>

<p align="justify">The issues abovementioned contribute to show that the portraits of white people tend to be more accurately represented than the other groups or at least that the respective generated pictures are closer to the original models. As the canonical aesthetic of Early Italian Renaissance is almost entirely based on the depiction of white people, this is unsurprising. 
  
<img style="display: block;-webkit-user-select: none;margin: auto;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decodingbiases/main/assets/figure_4.png">
  
<b>Original pictures and generations, references of the images (link to right and top to bottom): #654, #623, #37, #3870</b>

<p align="justify">The paintings used by AI Gahaku to train the model are most likely based on Antonello da Messina’s work, as one of his paintings is used illustrate the style of images that will be produced when selecting the style. After checking his work through the art database Wikiart (2022) , we did not find a single painting representing a non-white person. This could potentially explain the shortcomings of the models to generate pictures representing people from different ethnicities. 
As mentioned in our methodological part, to see whether those issues would be mitigated by applying an art style that potentially used more inclusive dataset for training, we subsequently generated portraits using the Contemporary Realism style. Amongst the options offered by AI Gahaku, we hypothesized that it could potentially produce less biased results than Early Renaissance. 
The results are, however, practically identical. This is notably visible when looking at the skin complexions of the second round of generations. The complexions are similar to the sample image provided for Contemporary Realism but disregards the skin colour of the pictures selected to produce a white complexion. 

 <img style="display: block;-webkit-user-select: none;margin: auto;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decodingbiases/main/assets/figure_5.png">

<b>Original pictures and generations *Contemporary Realism*, references of the images (link to right and top to bottom): #120, #1370, #4605, #6765</b>
  
<img style="display: block;-webkit-user-select: none;margin: auto;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decodingbiases/main/assets/figure_6.png"><b> Portrait #3718 & #3623 and juxtaposition of the real picture (black frame) on the generated portrait – <i> Contemporary Realism </i> </b>
<br>
The previous findings on eye shapes remain similar when observing images generated with the Contemporary Realism style. Frome these results, we can infer that the training data used for Contemporary Realism also lacked inclusivity. However, to better understand the causes of the biases produced by AI Gahaku, it is necessary to describe more precisely how the generations were created. 
  
AI Gahaku creator’s does not provide any explanation pertaining to the type of model used to create the paintings. The most likely way to create such generations would be through unpaired image-to-image translation using generative adversarial networks (GAN). One of the most widespread technologies to generate art are paired adversarial network. GANs are based on the interaction between generative neural network and a discriminator one. The generative network creates images attempting to recreate the demanded output convincingly and those are passed through the discriminator network which attempt to identify whether they are accurate or not. Both networks learn and improve together and use pairs of images (inputs and outputs) to learn the expected results. 
  
In the case of AI Gahaku, such pairs do not exist as the paintings that are replicated have no direct picture equivalents. Zhu & al. (2017) explain that another method allows to capture the characteristics of an input dataset and translate it into an output dataset without having paired, labelled images. They use unpaired training data: consisting of a source set<img style="display: block;-webkit-user-select: none;margin: auto;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decodingbiases/main/assets/equation.png"> and a target set <img style="display: block;-webkit-user-select: none;margin: auto;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decodingbiases/main/assets/equation2.png">with no information provided as to which x_i matches which y_j (Zhu & al. 2017). Using unpaired data of two datasets with similar characteristics is sufficient to train models to convincingly transfer the style of the base dataset to the model.

<img style="display: block;-webkit-user-select: none;margin: auto;cursor: zoom-in;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decodingbiases/main/assets/img_translation.jpg">
<b>Paired and unpaired training data, retrieved from Zhu & Al. 2017, p. 2</b>
  
<p>AI Gahaku’s model was highly likely also trained with unpaired data, using paintings as the input X and portraits as output Y. By looking at our findings, we can infer that not only the portraits used to train the model excluded non-white people but it is likely that output images were also biased. </p>

## Discussion 

<p align="justify">Now that we have analyzed the results generated by AI Gahaku and concluded there are less accurate paintings generated for non-white faces, we will investigate the extent to which these outcomes may originate from the paintings database by analysing the characteristics of the painting movements inspiring the Early Renaissance and Contemporary Realism filters. </p>
<b>1. Overview of the art movements inspiring AI Gahaku's filters</b><br>

<b> Early Renaissance Art </b>

<div align="center"><img crossorigin="anonymous" src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Antonello_da_Messina_-_Portrait_of_a_Man_-_National_Gallery_London.jpg/800px-Antonello_da_Messina_-_Portrait_of_a_Man_-_National_Gallery_London.jpg" class="jpg" alt="Antonello da Messina - Portrait of a Man - National Gallery London.jpg" width="473" height="657" style=""></div>
<b><div align="center">Portrait of a man (previously considered an autoportrait), painted by Antonello di Messine (1430-1479), dated 1473-1474</div></b>


<p align="justify">Antonello di Messine was an Italian painter of the Early Italian Renaissance. Though he was from the South of Italy (Messina), his work was influential throughout Italy. His style is known for integrating the details of Early Flemish artists into traditional Italian painting. As can be seen below, his works is overwhelmingly composed of white subjects or religious scenes.</p>

<img style="display: block;-webkit-user-select: none;margin: auto;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decoding_biases-final_project/main/assets/image.png">
<b>Antonello di Messine, painting, retrieved from Wikiart's database </b>
<br>
<p align="justify">His work is quite representative of Early Italian Renaissance (1400–1495) paintings. During this period, the visual arts underwent a major transition from two to three dimensions. The Early Renaissance also marks a shift with the representation of religion in art. Though people remained devoted to Christianity and the visual arts continued to represent biblical stories, painters and sculptors began to place a greater importance on man’s greatness by representing the human body in anatomical detail. In painting, the Early Renaissance style is characterized by the focus on the realism and naturalism of figures, depth and dimension of spaces using foreshortening and one-point perspective, dramatic emphasis through chiaroscuro (shading to create depth between light and dark parts). Significant artists include Filippo Brunelleschi (1377 – 1446), Sandro Botticelli (1445 – 1510), Masaccio (1401 – 1428) and Piero della Francesca (1420 – 1492). </p> 

<b> Contemporary Realism </b>

<p align="justify">We were unable to find the exact artist which inspired the filter by looking through AI Gahaku’s platform or through reverse searching the image associated to the filter. Nevertheless, the main tenets of the style are the following. The Tate describes “modern realism” as paintings or sculptures depicting things in a realistic manner, which were created since the emergence of abstract art.   Emerging out of New York in the late 1960s and early 70s, Contemporary Realism is intended as a contestation and a response to Abstract Expressionism. The movement shifts away from abstract representations of life in order to depict reality, but in a different way to 19th century realists. For instance, these new artists were known for representing modern urban and rural life, particularly around New York, but without the sentimentality of previous realists. Instead, they often used peoples’ gazes or still lifes to inform on their own lives. Significant artists include Jane Freilicher (1924-2014), Fairfield Porter (1907 - 1975), Alex Katz (1927 - ) and Leland Bell (1922 - 1991),  Philip Pearlstein (1924 - ), Jack Beal (1931- 2013) and Neil Welliver (1929-2005).</p>

<div align="center"> <img style="display: block;-webkit-user-select: none;margin: auto;cursor: zoom-in;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decoding_biases-final_project/main/assets/contemporary_realism.jpeg" width="618" height="929"></div>
<b><div align="center">Contemporary Realist Paintings; Blue Umbrella 2 , Alex Katz,1972; Portrait of John Ashbery, Jane Freilicher, 1968;Nidah, Nanette Fluhr, 2014; The Mirror, Fairfield Porter, 1966;Family Group with Butterfly, Leland Bell, 1986–1990; The Group, Leland Bell, 1976; sans titre (9578), Alex Katz; Portrait of Don Cord, Fairfield Porter, 1967; Portrait of Robert Dash, Fairfield Porter,1960; Girl and Geranium, Fairfield Porter, 1963</div></b>
<br>
<b>2. Observations </b>


<p align="justify">Upon researching the paintings associated with the Early Renaissance, it becomes quite evident that there is an underrepresentation of the faces of non-white people. There also seems to be more men represented than women. These observations align with the historical context of 15th century Florence. Our findings suggest AI Gahaku did not consider the lack of diversity in the dataset or did not properly weigh the importance of paintings with non-white faces against paintings representing white faces when building the training dataset. Furthermore, it is also likely that the input datasets (real portraits) used to train the models also lacked representativity.</p>

<p align="justify">Furthermore, even though Contemporary Realist paintings might still represent a majority of white people, our observation shows that it would be possible to create inclusive datasets of this style of painting. The movement being historically situated at a time of social movements which contested the invisibilization of non-white populations in the United States, many diverse representations can be found, which grounded our initial assumption that the style would present a lesser occurrence of biases. As the results were similarly biased, we can infer that AI Gahaku’s creators did not make a specific effort to create a model void of biases. A disclaimer on the website even warns about their potential presence. The portrait used as a template for the art styIe on the app represents a man likely of East Asian descent which could show that the authors of the model are attempting to remediate to those problems. </p>


## Conclusion and Limitations 


<p align="justify"> In conclusion, after comparing the portraits generated by AI Gahaku using the Early Renaissance and Contemporary Realism filters on white and non-white faces, we have concluded that the portraits generated are indeed less accurate when the initial photo is of a non-white face. Our work provides complementary evidence of the inaccuracy of CG art to match non-white faces with artwork, as was reported with the Google's Arts and Culture app intended to match selfies to works of art or AIPortraits. </p>

<p align="justify"> We believe these results stem from racially biased datasets. Indeed, our methodology leads us to believe that AI Gahaku was most likely trained with unpaired data, using faces as the input and portrait paintings as the output. Given the disparity of the results when the input was a white face and when it wasn’t, we believe neither the dataset used for the inputs/the photos of the faces, nor the outputs/the paintings were both tested for racial biases.</p>

<p align="justify"> Nevertheless, given that the code of AI Gahaku is not open source, we chose to analyze inputs and outputs to attempt to understand how AI Gahaku functions and where the racial bias may lie. It is however possible that having access to the code and thus being able to know what datasets of paintings and of faces were used to train the algorithm would have led us to other conclusions. For instance, we could conclude that only one of the two datasets is biased or be able to better evaluate how much weight each dataset has in provoking the biased outcomes for the East Asian and Black faces. </p>

<p align="justify"> Our research suggests the importance of accounting for biases in artistic history for other face-transforming AI and other CG-art. Further research could focus on how to produce painting or art datasets, which preserve the spirit and reality of the artistic movement or style, while accounting for the potential gender and racial biases which it could cause, upon use in CG art. The effects of weighting different paintings differently to create more diversity and representation in the dataset could be explored.</p>





## References


- Antonello de Messine - 41 œuvres d'art - peinture. www.wikiart.org. (n.d.). Retrieved November 30, 2022, from https://www.wikiart.org/fr/antonello-de-messine 


- Artincontext. (2022, November 16). Early Renaissance - exploring the early italian renaissance art period. artincontext.org. Retrieved November 20, 2022, from https://artincontext.org/early-renaissance/ 

- Contemporary Realism Movement Overview. The Art Story. (2022). Retrieved November 20, 2022, from https://www.theartstory.org/movement/contemporary-realism/ 


- Early Renaissance art and architecture. The Art Story. (2022). Retrieved November 30, 2022, from https://www.theartstory.org/movement/early-renaissance/ 


- Edmonds, Ernest A.. Boden, Margaret A.. “What is generative art”, Digital Creativity. March 2009: DOI: 10.1080/14626260902867915 Hertzmann, Aaron.. "Can Computers Create Art?" Arts 7, no. 2: 18. February 2018 https://doi.org/10.3390/arts7020018 


- Goodfellow, Ian J. Pouget-Abadie, Jean. Mirza, Mehdi. Xu, Bing. Warde-Farley, David. Ozair, Sherjil. Courville, Aaron. Bengio, Yoshua. “Generative Adversarial Networks”, Arxiv. June 2014: https://doi.org/10.48550/arXiv.1406.2661

- Hardesty, Larry. “Study finds gender and skin-type bias in commercial artificial-intelligence systems”, MIT News. February 2018: https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212

- Jun-Yan Zhu*, Taesung Park*, Phillip Isola, and Alexei A. Efros. "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks", in IEEE International Conference on Computer Vision (ICCV), 2017.

- Karkkainen, K., & Joo, J. (2021). FairFace: Face Attribute Dataset for Balanced Race, Gender, and Age for Bias Measurement and Mitigation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1548-1558). 

- Ongweso Jr, Edward. “Racial Bias in AI Isn’t Getting Better and Neither Are Researchers’ Excuses.” Vice, 29 July 2019, https://www.vice.com/en/article/8xzwgx/racial-bias-in-ai-isnt-getting-better-and-neither-are-researchers-excuses. Accessed 18 Nov. 2022. 

- Rea, Naomi. “How ImageNet Roulette, an Art Project That Went Viral by Exposing Facial Recognition’s Biases, Is Changing People’s Minds About AI.”, Artnet News. September 2019: https://news.artnet.com/art-world/imagenet-roulette-trevor-paglen-kate-crawford-1658305 

- Realism Today. (2022, June 30). What is contemporary realism in art? Realism Today. Retrieved November 30, 2022, from https://realismtoday.com/what-is-contemporary-realism-in-art/ 
Sung, Morgan. “The AI Renaissance Portrait Generator Isn't Great at Painting People of Color.” Mashable, 19 July 2019, https://mashable.com/article/ai-portrait-generator-pocs. Accessed 18 Nov. 2022. 

- Srinivasan, Ramya. Uchino, Kanji. “Biases in Generative Art— A Causal Look from the Lens of Art History”, FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. March 2021. Pages 41–51: https://doi.org/10.1145/3442188.3445869 

- Young, David. Tabula Rasa: Rethinking the Intelligence of Machine Minds. 2019 https://medium.com/@dkyy/tabula-rasa-b5f846e6085


## Appendices 

<img style="display: block;-webkit-user-select: none;margin: auto;cursor: zoom-in;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decodingbiases/main/1%20-%20Black%20-%20All%20generations.png" >
<b>Group 1 - Black - Generations in both styles and original pictures</b> <br>

<img style="display: block;-webkit-user-select: none;margin: auto;cursor: zoom-in;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decoding_biases-final_project/main/2%20-%20East%20Asian%20-%20All%20generations.png" >
<b>Group 2 - East Asian - Generations in both styles and original picture</b> <br>

<img style="display: block;-webkit-user-select: none;margin: auto;cursor: zoom-in;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;" src="https://raw.githubusercontent.com/lioprd/decoding_biases-final_project/main/3%20-%20White%20-%20All%20generations.png">
<b>Group 3 - White - Generations in both styles and original picture</b> <br>

